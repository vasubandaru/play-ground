{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different ways to do Linear regression in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### References\n",
    "# https://medium.freecodecamp.org/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b\n",
    "# https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scipy.Polyfit\n",
    "Stats.linregress\n",
    "Optimize.curve_fit\n",
    "numpy.linalg.lstsq\n",
    "statsmodels.OLS\n",
    "Analytic solution using Moore-Penrose generalized inverse or simple multiplicative matrix inverse\n",
    "sklearn.linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Load dataset from sklearn\n",
    "from sklearn import datasets\n",
    "data = datasets.load_boston()\n",
    "\n",
    "print(type(data)) #Gives a data of type Bunch(what ?)\n",
    "print(data.DESCR)\n",
    "print(data.feature_names) #Get feature names\n",
    "print(data.target) # Print Target data\n",
    "print(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n",
      "   MEDV\n",
      "0  24.0\n",
      "1  21.6\n",
      "2  34.7\n",
      "3  33.4\n",
      "4  36.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Data - features\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "print(df.head())\n",
    "\n",
    "#Data - Target variable\n",
    "Target = pd.DataFrame(data.target,columns = ['MEDV'])\n",
    "print(Target.head())\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f1af15ff60>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f1aeef7860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df['AGE'],Target['MEDV'],'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Scipy.Polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function polyfit in module numpy.lib.polynomial:\n",
      "\n",
      "polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)\n",
      "    Least squares polynomial fit.\n",
      "    \n",
      "    Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`\n",
      "    to points `(x, y)`. Returns a vector of coefficients `p` that minimises\n",
      "    the squared error.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like, shape (M,)\n",
      "        x-coordinates of the M sample points ``(x[i], y[i])``.\n",
      "    y : array_like, shape (M,) or (M, K)\n",
      "        y-coordinates of the sample points. Several data sets of sample\n",
      "        points sharing the same x-coordinates can be fitted at once by\n",
      "        passing in a 2D-array that contains one dataset per column.\n",
      "    deg : int\n",
      "        Degree of the fitting polynomial\n",
      "    rcond : float, optional\n",
      "        Relative condition number of the fit. Singular values smaller than\n",
      "        this relative to the largest singular value will be ignored. The\n",
      "        default value is len(x)*eps, where eps is the relative precision of\n",
      "        the float type, about 2e-16 in most cases.\n",
      "    full : bool, optional\n",
      "        Switch determining nature of return value. When it is False (the\n",
      "        default) just the coefficients are returned, when True diagnostic\n",
      "        information from the singular value decomposition is also returned.\n",
      "    w : array_like, shape (M,), optional\n",
      "        Weights to apply to the y-coordinates of the sample points. For\n",
      "        gaussian uncertainties, use 1/sigma (not 1/sigma**2).\n",
      "    cov : bool, optional\n",
      "        Return the estimate and the covariance matrix of the estimate\n",
      "        If full is True, then cov is not returned.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    p : ndarray, shape (deg + 1,) or (deg + 1, K)\n",
      "        Polynomial coefficients, highest power first.  If `y` was 2-D, the\n",
      "        coefficients for `k`-th data set are in ``p[:,k]``.\n",
      "    \n",
      "    residuals, rank, singular_values, rcond\n",
      "        Present only if `full` = True.  Residuals of the least-squares fit,\n",
      "        the effective rank of the scaled Vandermonde coefficient matrix,\n",
      "        its singular values, and the specified value of `rcond`. For more\n",
      "        details, see `linalg.lstsq`.\n",
      "    \n",
      "    V : ndarray, shape (M,M) or (M,M,K)\n",
      "        Present only if `full` = False and `cov`=True.  The covariance\n",
      "        matrix of the polynomial coefficient estimates.  The diagonal of\n",
      "        this matrix are the variance estimates for each coefficient.  If y\n",
      "        is a 2-D array, then the covariance matrix for the `k`-th data set\n",
      "        are in ``V[:,:,k]``\n",
      "    \n",
      "    \n",
      "    Warns\n",
      "    -----\n",
      "    RankWarning\n",
      "        The rank of the coefficient matrix in the least-squares fit is\n",
      "        deficient. The warning is only raised if `full` = False.\n",
      "    \n",
      "        The warnings can be turned off by\n",
      "    \n",
      "        >>> import warnings\n",
      "        >>> warnings.simplefilter('ignore', np.RankWarning)\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    polyval : Compute polynomial values.\n",
      "    linalg.lstsq : Computes a least-squares fit.\n",
      "    scipy.interpolate.UnivariateSpline : Computes spline fits.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The solution minimizes the squared error\n",
      "    \n",
      "    .. math ::\n",
      "        E = \\sum_{j=0}^k |p(x_j) - y_j|^2\n",
      "    \n",
      "    in the equations::\n",
      "    \n",
      "        x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
      "        x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]\n",
      "        ...\n",
      "        x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]\n",
      "    \n",
      "    The coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n",
      "    \n",
      "    `polyfit` issues a `RankWarning` when the least-squares fit is badly\n",
      "    conditioned. This implies that the best fit is not well-defined due\n",
      "    to numerical error. The results may be improved by lowering the polynomial\n",
      "    degree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter\n",
      "    can also be set to a value smaller than its default, but the resulting\n",
      "    fit may be spurious: including contributions from the small singular\n",
      "    values can add numerical noise to the result.\n",
      "    \n",
      "    Note that fitting polynomial coefficients is inherently badly conditioned\n",
      "    when the degree of the polynomial is large or the interval of sample points\n",
      "    is badly centered. The quality of the fit should always be checked in these\n",
      "    cases. When polynomial fits are not satisfactory, splines may be a good\n",
      "    alternative.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Wikipedia, \"Curve fitting\",\n",
      "           http://en.wikipedia.org/wiki/Curve_fitting\n",
      "    .. [2] Wikipedia, \"Polynomial interpolation\",\n",
      "           http://en.wikipedia.org/wiki/Polynomial_interpolation\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
      "    >>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
      "    >>> z = np.polyfit(x, y, 3)\n",
      "    >>> z\n",
      "    array([ 0.08703704, -0.81349206,  1.69312169, -0.03968254])\n",
      "    \n",
      "    It is convenient to use `poly1d` objects for dealing with polynomials:\n",
      "    \n",
      "    >>> p = np.poly1d(z)\n",
      "    >>> p(0.5)\n",
      "    0.6143849206349179\n",
      "    >>> p(3.5)\n",
      "    -0.34732142857143039\n",
      "    >>> p(10)\n",
      "    22.579365079365115\n",
      "    \n",
      "    High-order polynomials may oscillate wildly:\n",
      "    \n",
      "    >>> p30 = np.poly1d(np.polyfit(x, y, 30))\n",
      "    /... RankWarning: Polyfit may be poorly conditioned...\n",
      "    >>> p30(4)\n",
      "    -0.80000000000000204\n",
      "    >>> p30(5)\n",
      "    -0.99999999999999445\n",
      "    >>> p30(4.5)\n",
      "    -0.10547061179440398\n",
      "    \n",
      "    Illustration:\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> xp = np.linspace(-2, 6, 100)\n",
      "    >>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n",
      "    >>> plt.ylim(-2,2)\n",
      "    (-2, 2)\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import polyfit\n",
    "\n",
    "help(polyfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression output using ployfit\n",
      "parameters: Intercept=30.98 slope=-0.12, MSE = 5.67\n"
     ]
    }
   ],
   "source": [
    "#Data - Input and Output\n",
    "x = df['AGE']\n",
    "y = Target['MEDV']\n",
    "n = x.size\n",
    "\n",
    "#Run the regression\n",
    "(b1,b0) = polyfit(x,y,1)\n",
    "\n",
    "#Error\n",
    "ypred = b0 + b1*y\n",
    "err = (np.sqrt(sum(ypred - y)**2)/n)\n",
    "\n",
    "print(\"Linear regression output using ployfit\")\n",
    "print('parameters: Intercept=%.2f slope=%.2f, MSE = %.2f' % (b0,b1,err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  stats.linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linregress in module scipy.stats._stats_mstats_common:\n",
      "\n",
      "linregress(x, y=None)\n",
      "    Calculate a linear least-squares regression for two sets of measurements.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x, y : array_like\n",
      "        Two sets of measurements.  Both arrays should have the same length.\n",
      "        If only x is given (and y=None), then it must be a two-dimensional\n",
      "        array where one dimension has length 2.  The two sets of measurements\n",
      "        are then found by splitting the array along the length-2 dimension.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    slope : float\n",
      "        slope of the regression line\n",
      "    intercept : float\n",
      "        intercept of the regression line\n",
      "    rvalue : float\n",
      "        correlation coefficient\n",
      "    pvalue : float\n",
      "        two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "        that the slope is zero, using Wald Test with t-distribution of\n",
      "        the test statistic.\n",
      "    stderr : float\n",
      "        Standard error of the estimated gradient.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    :func:`scipy.optimize.curve_fit` : Use non-linear\n",
      "     least squares to fit a function to data.\n",
      "    :func:`scipy.optimize.leastsq` : Minimize the sum of\n",
      "     squares of a set of equations.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from scipy import stats\n",
      "    >>> np.random.seed(12345678)\n",
      "    >>> x = np.random.random(10)\n",
      "    >>> y = np.random.random(10)\n",
      "    >>> slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
      "    \n",
      "    To get coefficient of determination (r_squared)\n",
      "    \n",
      "    >>> print(\"r-squared:\", r_value**2)\n",
      "    r-squared: 0.080402268539\n",
      "    \n",
      "    Plot the data along with the fitted line\n",
      "    \n",
      "    >>> plt.plot(x, y, 'o', label='original data')\n",
      "    >>> plt.plot(x, intercept + slope*x, 'r', label='fitted line')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "help(stats.linregress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression output using lingress\n",
      "parameters: Intercept =30.98 slope=-0.12, R-square = -0.38, Std.error = 0.01\n"
     ]
    }
   ],
   "source": [
    "#Data - Input and Output\n",
    "x = df['AGE']\n",
    "y = Target['MEDV']\n",
    "n = x.size\n",
    "\n",
    "(b1,b0,R2,pvalue,stderr)= stats.linregress(x,y)\n",
    "\n",
    "print(\"Linear regression output using lingress\")\n",
    "print('parameters: Intercept =%.2f slope=%.2f, R-square = %.2f, Std.error = %.2f' % (b0,b1,R2,stderr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
